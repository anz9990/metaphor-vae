{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/projects/jadlg_rnn/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>text</th>\n",
       "      <th>dictionary</th>\n",
       "      <th>context</th>\n",
       "      <th>provenance</th>\n",
       "      <th>comments</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>created_at</th>\n",
       "      <th>theme</th>\n",
       "      <th>id</th>\n",
       "      <th>reviewed_on</th>\n",
       "      <th>metaphor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3213.0</td>\n",
       "      <td>Logitians use to clap a Proposition,&lt;br&gt;\\r\\n A...</td>\n",
       "      <td>Animals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Searching \"rule\" and \"reason\" in HDIS (Poetry)</td>\n",
       "      <td>In this case, not fish-trap as I originally th...</td>\n",
       "      <td>2013-10-04 14:27:45 UTC</td>\n",
       "      <td>2004-06-10 00:00:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8442</td>\n",
       "      <td>2011-06-14</td>\n",
       "      <td>A Logician is \"one, that has been broke / To R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3323.0</td>\n",
       "      <td>What raisd their Joy their love coud also rais...</td>\n",
       "      <td>Impression</td>\n",
       "      <td>I've included the entire poem</td>\n",
       "      <td>Searching \"soul\" and \"impression\" in HDIS (Poe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-09-14 19:33:39 UTC</td>\n",
       "      <td>2005-05-17 00:00:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Deep in their soules ye fair impression lay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3324.0</td>\n",
       "      <td>&lt;b&gt;If at the type our dreaming soules awake,&lt;B...</td>\n",
       "      <td>Impression</td>\n",
       "      <td>I've included the entire poem</td>\n",
       "      <td>Searching \"soul\" and \"impression\" in HDIS (Poe...</td>\n",
       "      <td>&lt;BR&gt;</td>\n",
       "      <td>2009-09-14 19:33:39 UTC</td>\n",
       "      <td>2005-05-17 00:00:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"If at the type our dreaming soules awake, / &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3407.0</td>\n",
       "      <td>In all mistakes, The Strickt, and Regular,&lt;BR&gt;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Searching \"mind\" and \"clock\" in HDIS (Poetry)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-09-14 19:33:43 UTC</td>\n",
       "      <td>2006-11-16 00:00:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"As no Man mind's those Clocks that use to go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5026.0</td>\n",
       "      <td>\"Edward, lo! to sudden fate &lt;BR&gt;\"(Weave we the...</td>\n",
       "      <td>Inhabitants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-09-14 19:38:37 UTC</td>\n",
       "      <td>2003-11-11 00:00:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unborn ages may crowd on the soul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_id                                               text   dictionary  \\\n",
       "0   3213.0  Logitians use to clap a Proposition,<br>\\r\\n A...      Animals   \n",
       "1   3323.0  What raisd their Joy their love coud also rais...   Impression   \n",
       "2   3324.0  <b>If at the type our dreaming soules awake,<B...   Impression   \n",
       "3   3407.0  In all mistakes, The Strickt, and Regular,<BR>...          NaN   \n",
       "4   5026.0  \"Edward, lo! to sudden fate <BR>\"(Weave we the...  Inhabitants   \n",
       "\n",
       "                         context  \\\n",
       "0                            NaN   \n",
       "1  I've included the entire poem   \n",
       "2  I've included the entire poem   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "\n",
       "                                          provenance  \\\n",
       "0     Searching \"rule\" and \"reason\" in HDIS (Poetry)   \n",
       "1  Searching \"soul\" and \"impression\" in HDIS (Poe...   \n",
       "2  Searching \"soul\" and \"impression\" in HDIS (Poe...   \n",
       "3      Searching \"mind\" and \"clock\" in HDIS (Poetry)   \n",
       "4                                               HDIS   \n",
       "\n",
       "                                            comments               updated_at  \\\n",
       "0  In this case, not fish-trap as I originally th...  2013-10-04 14:27:45 UTC   \n",
       "1                                                NaN  2009-09-14 19:33:39 UTC   \n",
       "2                                               <BR>  2009-09-14 19:33:39 UTC   \n",
       "3                                                NaN  2009-09-14 19:33:43 UTC   \n",
       "4                                                NaN  2009-09-14 19:38:37 UTC   \n",
       "\n",
       "                created_at theme     id reviewed_on  \\\n",
       "0  2004-06-10 00:00:00 UTC   NaN   8442  2011-06-14   \n",
       "1  2005-05-17 00:00:00 UTC   NaN   8591         NaN   \n",
       "2  2005-05-17 00:00:00 UTC   NaN   8592         NaN   \n",
       "3  2006-11-16 00:00:00 UTC   NaN   8698         NaN   \n",
       "4  2003-11-11 00:00:00 UTC   NaN  13518         NaN   \n",
       "\n",
       "                                            metaphor  \n",
       "0  A Logician is \"one, that has been broke / To R...  \n",
       "1  \"Deep in their soules ye fair impression lay, ...  \n",
       "2  \"If at the type our dreaming soules awake, / &...  \n",
       "3  \"As no Man mind's those Clocks that use to go ...  \n",
       "4                  Unborn ages may crowd on the soul  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'all.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text'].astype(str)\n",
    "metaphor = df['metaphor'].astype(str)\n",
    "text = [t.lower().replace('\\r','').replace('/','').replace('\"','').replace(\"'\",\"\").replace(\"\\n\",\"\").replace('<br>','').replace('<i>','').replace('--','') for t in text]\n",
    "metaphor = [t.lower().replace('\\r','').replace('/','').replace('\"','').replace(\"'\",\"\").replace(\"\\n\",\"\").replace('<br>','').replace('<i>','').replace('--','') for t in metaphor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0, c1 = [],[]\n",
    "\n",
    "for i in range(len(text)):\n",
    "    text[i] = re.sub('\\x0b','',text[i])\n",
    "    t = re.sub('<b>.*<b>',' xxmsk ',text[i]).split(' xxmsk ')\n",
    "    c0.append(t[0])\n",
    "    if len(t) > 1:  c1.append(t[1])\n",
    "    else: c1.append('')\n",
    "    #text[i] = re.sub('<.*>','',text[i])\n",
    "    #metaphor[i] = re.sub('<.*>','',metaphor[i])\n",
    "    #text[i] = re.sub('\\x0b','',text[i])\n",
    "    metaphor[i] = re.sub('\\x0b','',metaphor[i])\n",
    "    #text[i].replace('.(p','')\n",
    "    #text[i].replace(' ','')\n",
    "    #text[i].replace('.(pp','')\n",
    "    \n",
    "    #metaphor[i] = re.sub('(.*)','',metaphor[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the verse adorn again fierce war and faithful love, and truth severe, by fairy fiction dressed. in buskined measures move pale grief and pleasing pain, with ',\n",
       " '.a voice as of the cherub-choir gales from blooming eden bear; and distant warblings lessen on my ear, that lost in long futurity expire. fond impious man, thinkst thou yon sanguine cloud, raised by thy breath, has quenched the orb of day? tomorrow he repairs the golden flood, and warms the nations with redoubled ray. enough for me: with joy i see the different doom our fates assign. be thine despair and sceptered care; to triumph, and to die, are mine. he spoke, and headlong from the mountains height deep in the roaring tide he plunged to endless night. (ll. 125-44, pp. 198-200)',\n",
       " 'horror may be a tyrant of the throbbing breast')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0[5],c1[5],metaphor[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14957"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_c0 = Tokenizer.proc_all(c0,lang='en')\n",
    "tok_c1 = Tokenizer.proc_all(c1,lang='en')\n",
    "tok_tgt = Tokenizer.proc_all(metaphor,lang='en')\n",
    "len(tok_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tok_src[0], tok_tgt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def mask_sequences(texts):\n",
    "#    masked_text = []\n",
    "#    for text in texts:\n",
    "#        for token in tokenizer.tok(text):\n",
    "#            if token.pos_ == 'VERB' and not token.is_stop:\n",
    "#                text = text.replace(str(token),' xxmsk ')\n",
    "#        masked_text.append(text)\n",
    "#    return masked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masked_metaphor = mask_sequences(metaphor)\n",
    "#masked_metaphor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masked_metaphor = [text.replace(' xxmsk ','xxmsk') for text in masked_metaphor]\n",
    "#masked_metaphor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(masked_metaphor, open(path/'metaphors_masked.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masked_metaphor = pickle.load(open(path/'metaphors_masked.pkl','rb'))\n",
    "#len(masked_metaphor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def toks2ids(tok, pre,is_src=True,ovrt=False):\n",
    "    if ovrt:\n",
    "        freq = collections.Counter(p for o in tok for p in o)\n",
    "        itos = [o for o,c in freq.most_common(20000)]\n",
    "        itos.insert(0, 'xxunk')\n",
    "        itos.insert(1, 'xxpad')\n",
    "        itos.insert(2, 'xxbos')\n",
    "        #itos.insert(3, 'xxmsk')\n",
    "        stoi = collections.defaultdict(lambda: 0, {v:k for k,v in enumerate(itos)})\n",
    "        pickle.dump(itos, open(path/f'{pre}_itos.pkl', 'wb'))\n",
    "    else: \n",
    "        itos = pickle.load(open(path/f'{pre}_itos.pkl', 'rb'))\n",
    "        stoi = collections.defaultdict(lambda: 0, {v:k for k,v in enumerate(itos)})\n",
    "    return itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tok_src = Tokenizer.proc_all(masked_metaphor,lang='en')\n",
    "#tok_tgt = Tokenizer.proc_all(metaphor,lang='en')\n",
    "#len(tok_src), len(tok_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20003, 14957, 14957)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos,stoi = toks2ids(tok_c0+tok_c1+tok_tgt,'metaphors',ovrt=True)\n",
    "#itos,stoi = toks2ids(tok_tgt,'metaphors',ovrt=False)\n",
    "c0_ids = np.array([[2]+[stoi[o] for o in p] for p in tok_c0])\n",
    "c1_ids = np.array([[2]+[stoi[o] for o in p] for p in tok_c1])\n",
    "tgt_ids = np.array([[2]+[stoi[o] for o in p] for p in tok_tgt])\n",
    "len(itos),len(c0_ids),len(tgt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#c0_ids[0], tgt_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_c0,val_c0,trn_c1,val_c1,trn_tgt,val_tgt = sklearn.model_selection.train_test_split(c0_ids,c1_ids,tgt_ids,test_size=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13461, 13461, 1496, 1496)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_c0), len(trn_tgt), len(val_c0), len(val_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_c0[:2], trn_c1[:2],trn_tgt[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    header = fin.readline().split()\n",
    "    n, d = header[0], header[1]\n",
    "    data = {}\n",
    "    #partitions = [fin[:]]\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(tokens[1:], dtype=float)\n",
    "    return data, n, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs, vs, dim_en_vec = load_vectors('/home/paperspace/projects/seq2seq_bot/data/wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, c0, c1,tgt):\n",
    "        self.c0 = c0\n",
    "        self.c1 = c1\n",
    "        self.tgt = tgt\n",
    "        self.ml = 100\n",
    "    def __getitem__(self, idx):\n",
    "        return A(self.c0[idx][-self.ml:]), A(self.c1[idx][-self.ml:]), A(self.tgt[idx][-self.ml:]),A(self.tgt[idx][-self.ml:])\n",
    "    def __len__(self): return len(self.src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_seq2seq_ds = MaskDataset(trn_c0,trn_c1,trn_tgt)\n",
    "val_seq2seq_ds = MaskDataset(val_c0,val_c1,val_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64\n",
    "\n",
    "trn_samp = SortishSampler(trn_c0, lambda x: len(trn_c0[x]), bs)\n",
    "val_samp = SortSampler(val_c0, lambda x: len(val_c0[x]))\n",
    "\n",
    "trn_seq2seq_dl = DataLoader(trn_seq2seq_ds,batch_size=bs,pad_idx=1,num_workers=1,pre_pad=False, transpose_y=True, transpose=True, sampler=trn_samp)\n",
    "val_seq2seq_dl = DataLoader(val_seq2seq_ds,batch_size=bs,pad_idx=1,num_workers=1,pre_pad=False, transpose_y=True, transpose=True, sampler=val_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 64]),\n",
       " torch.Size([100, 64]),\n",
       " torch.Size([64, 100]),\n",
       " torch.Size([64, 100]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0, c1, x, y = next(iter(trn_seq2seq_dl))\n",
    "c0.size(), c1.size(), x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ModelData(path, trn_seq2seq_dl, val_seq2seq_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target, kld_weight=0):\n",
    "    decoded = input\n",
    "    sl, bs = target.size()\n",
    "    sl_in,bs_in,nc = decoded.size()\n",
    "    if sl>sl_in: decoded = F.pad(decoded, (0,0,0,0,0,sl-sl_in))\n",
    "    decoded = decoded[:sl]\n",
    "    return F.cross_entropy(decoded.view(-1,nc), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w])\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,vs,vecs,itos,em_sz,latent_sz,nh,nl=2, dropf=1,wdrop=0,kld_weight=1e-3):\n",
    "        super().__init__()\n",
    "        self.initrange=0.1\n",
    "        self.wdrop,self.kld_weight = wdrop,kld_weight\n",
    "        self.nl,self.nh, self.vs,self.em_sz,self.latent_sz = nl,nh,vs,em_sz,latent_sz\n",
    "        #encoder\n",
    "        self.emb_enc = create_emb(vecs,itos,em_sz)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15*dropf)\n",
    "        self.gru_enc = nn.GRU(em_sz, nh, num_layers=nl, dropout=0.25*dropf, bidirectional=True)\n",
    "        self.out_drop = nn.Dropout(0.35*dropf)\n",
    "        #latent space layers\n",
    "        self.h2m = nn.Linear(nh*nl*2*3, latent_sz)\n",
    "        self.h2m.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.h2log = nn.Linear(nh*nl*2*3, latent_sz)\n",
    "        self.h2log.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        #self.z2h = nn.Linear(latent_sz, nh*nl)\n",
    "        #self.z2h.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        #decoder\n",
    "        self.gru_dec = nn.GRU(em_sz+latent_sz, nh*2*3, num_layers=nl, dropout=0.25*dropf)\n",
    "        self.out = nn.Linear(nh*2*3, vs)\n",
    "        self.out.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.pr_force = 1.\n",
    "        \n",
    "    def forward(self, inp, y=None):\n",
    "        #encode\n",
    "        c0,c1,x = inp\n",
    "        x = x.transpose(1,0)\n",
    "        sl,bs = x.size()\n",
    "        hidden = self.initHidden(bs) # nl*bs*nh\n",
    "        \n",
    "        emb1 = self.emb_enc_drop(self.emb_enc(c0)) #sl*bs*em_sz\n",
    "        _, hidden = self.gru_enc(emb1,hidden) #enc_out: sl*bs*nh, hidden: (2*nl)*bs*nh\n",
    "        h1 = hidden.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "        \n",
    "        emb2 = self.emb_enc_drop(self.emb_enc(x)) #sl*bs*em_sz\n",
    "        _, hidden = self.gru_enc(emb2,hidden) #enc_out: sl*bs*nh, hidden: (2*nl)*bs*nh\n",
    "        h2 = hidden.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "        \n",
    "        emb3 = self.emb_enc_drop(self.emb_enc(c1)) #sl*bs*em_sz\n",
    "        _, hidden = self.gru_enc(emb3,hidden) #enc_out: sl*bs*nh, hidden: (2*nl)*bs*nh\n",
    "        h3 = hidden.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "        \n",
    "        hidden = torch.cat([h1,h2,h3],2)\n",
    "        \n",
    "        mu,logvar = self.h2m(hidden.view(bs,-1)),self.h2log(hidden.view(bs,-1))\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = V(torch.randn(mu.size())) #bs*latent_sz\n",
    "        z = eps * std + mu #bs*latent_sz\n",
    "\n",
    "        #decode\n",
    "        #hidden = self.z2h(z).view(self.nl, bs, self.nh)\n",
    "        #hidden = self.initHidden(bs).view(self.nl,bs,self.nh*2)\n",
    "        dec_seq = x.clone()\n",
    "        #word dropout\n",
    "        if self.wdrop > 0: \n",
    "            prob = V(torch.rand(dec_seq.size())) \n",
    "            prob[(dec_seq.data - stoi['xxbos']) * (dec_seq.data - stoi['xxpad']) == 0] = 1\n",
    "            dec_seq[prob < self.wdrop] = stoi['xxunk']\n",
    "        \n",
    "        res = []\n",
    "        dec_inp = V(torch.zeros(bs)+stoi['xxbos']).long()\n",
    "        \n",
    "        for i in range(sl):\n",
    "            dec_emb = self.emb_enc(dec_inp)\n",
    "            gru_inp = torch.cat([dec_emb,z], 1).unsqueeze(0)\n",
    "            outp, hidden = self.gru_dec(gru_inp, hidden) #output: sl*bs*(nh*nl*2), hidden: (nl*2)*bs*nh\n",
    "            #hidden = hidden.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "            outp = self.out(self.out_drop(outp[0])) #bs*vs\n",
    "            res.append(outp)\n",
    "            if (random.random()>self.pr_force):\n",
    "                dec_inp = dec_seq[i]\n",
    "            else:\n",
    "                dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res), mu, logvar, z\n",
    "    \n",
    "    def inference(self,z):\n",
    "        res =[]\n",
    "        bs,_ = z.size()\n",
    "        #samples = V(torch.zeros(MAX_LENGTH, bs).long())\n",
    "        #z = V(torch.randn([bs, self.latent_sz]))\n",
    "        #hidden = self.z2h(z).view(self.nl, bs, self.nh)\n",
    "        hidden = h = V(torch.zeros(self.nl, bs, self.nh*2*3))\n",
    "        dec_inp = V(torch.zeros(bs)+stoi['xxbos']).long()\n",
    "        for i in range(MAX_LENGTH):\n",
    "            emb = self.emb_enc(dec_inp)\n",
    "            gru_inp = torch.cat([emb,z],1).unsqueeze(0)\n",
    "            outp, hidden = self.gru_dec(gru_inp, hidden)\n",
    "            \n",
    "            outp = self.out(outp[0])\n",
    "            res.append(outp)\n",
    "            #dec_inp = V(torch.topk(outp,1,-1)[1]).squeeze(1)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            outp = F.log_softmax(outp, dim=1)\n",
    "            outp = torch.multinomial(torch.exp(outp), 1)\n",
    "            #samples[i, :] = outp.view(-1).data\n",
    "            dec_inp = V(outp.view(-1))\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs):\n",
    "        h = V(torch.zeros(self.nl*2, bs, self.nh))\n",
    "        #if torch.cuda.is_available(): h = h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_anneal_function(anneal_function, step, k, x0):\n",
    "    if anneal_function == 'logistic':\n",
    "        return float(1/(1+np.exp(-k*(step-x0))))\n",
    "    elif anneal_function == 'linear':\n",
    "        return min(1, step/x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(input, target, kld_weight):\n",
    "    decoded, mu, logvar, z = input\n",
    "    sl, bs = target.size()\n",
    "    sl_in,bs_in,nc = decoded.size()\n",
    "    if sl>sl_in: decoded = F.pad(decoded, (0,0,0,0,0,sl-sl_in))\n",
    "    decoded = decoded[:sl]\n",
    "    #loss = seq2seq_loss(decoded, target)\n",
    "    loss = F.cross_entropy(decoded.view(-1,nc), target.contiguous().view(-1))\n",
    "    KL_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    loss += KL_loss * kld_weight\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEStepper(Stepper):\n",
    "    \n",
    "    def step(self, x, y, epoch, an_f='logistic',kld_start_inc=5):\n",
    "        xtra = []\n",
    "        #self.m.wdrop = 0.1 if epoch>4 else 0\n",
    "        self.m.pr_force = (10-epoch)*0.1 if epoch<10 else 0\n",
    "        y = y.transpose(1,0)\n",
    "        output = self.m(x, y)\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "        self.opt.zero_grad()\n",
    "        loss = raw_loss = self.crit([output]+xtra, y, self.m.kld_weight)\n",
    "        loss.backward()\n",
    "        if epoch > kld_start_inc:\n",
    "            self.m.kld_weight = kl_anneal_function(an_f,epoch,self.m.kld_weight,kld_start_inc)\n",
    "        if self.clip:   # Gradient clipping\n",
    "            nn.utils.clip_grad_norm_(trainable_params_(self.m), self.clip)\n",
    "        self.opt.step()\n",
    "        return raw_loss.data.item()\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        self.m.eval()\n",
    "        xtra = []\n",
    "        #x = x[0]\n",
    "        y = y.transpose(1,0)\n",
    "        output = self.m(x, y)\n",
    "        #decoded, m, l, z = output\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "#        loss = raw_loss = self.crit([output]+xtra,y, kld_weight)\n",
    "    \n",
    "        return output, self.crit([output]+xtra,y, self.m.kld_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2488 ['em>.', 'fancys', '.(p', 'formd', 'lovd']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (emb_enc): Embedding(20003, 300, padding_idx=1)\n",
       "  (emb_enc_drop): Dropout(p=0.15)\n",
       "  (gru_enc): GRU(300, 64, num_layers=2, dropout=0.25, bidirectional=True)\n",
       "  (out_drop): Dropout(p=0.35)\n",
       "  (h2m): Linear(in_features=768, out_features=16, bias=True)\n",
       "  (h2log): Linear(in_features=768, out_features=16, bias=True)\n",
       "  (gru_dec): GRU(316, 384, num_layers=2, dropout=0.25)\n",
       "  (out): Linear(in_features=384, out_features=20003, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nh = 64\n",
    "nl = 2\n",
    "vs = len(itos)\n",
    "em_sz = int(dim_en_vec)\n",
    "#latent_sz = em_sz\n",
    "latent_sz = 16\n",
    "vae = VAE(vs,en_vecs,itos,em_sz,latent_sz,nh,nl=nl)\n",
    "vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, SingleModel(to_gpu(vae)), opt_fn=opt_fn)\n",
    "learn.crit = vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db46e22a7eac47edba98993382f4e371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 133/211 [00:32<00:18,  4.12it/s, loss=11.9]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(stepper=VAEStepper)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f877f029fc4e9ca1b6cb312deafb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      9.165899   9.185358  \n",
      "    1      9.184658   9.132954                              \n",
      "    2      4.792736   4.896982                              \n",
      "    3      2.866191   4.572734                              \n",
      "    4      2.506885   2.271927                              \n",
      "    5      2.309175   2.195698                              \n",
      "    6      2.449613   2.387732                              \n",
      "    7      2.249486   2.357651                              \n",
      "    8      2.089488   2.102761                              \n",
      "    9      2.044205   2.017938                              \n",
      "    10     1.939814   1.933431                              \n",
      "    11     1.932937   1.90476                               \n",
      "    12     1.889286   1.877678                              \n",
      "    13     1.896869   1.867468                              \n",
      "    14     1.857419   1.844563                              \n",
      "    15     1.844263   1.830144                              \n",
      "    16     1.760891   1.828578                              \n",
      "    17     1.769075   1.811897                              \n",
      "    18     1.824628   1.811914                              \n",
      "    19     1.801172   1.792954                              \n",
      "    20     1.721493   1.786122                              \n",
      "    21     1.743284   1.779384                              \n",
      "    22     1.72455    1.772877                              \n",
      "    23     1.69216    1.769047                              \n",
      "    24     1.689501   1.766959                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7669588678023394]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=25, stepper=VAEStepper, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('vae_metaphors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('vae_metaphors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a7dbc8beaf4f989152cb7e53bc31c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      4.960727   5.174614  \n",
      "    1      4.278578   5.172833                              \n",
      "    2      4.844539   5.17032                               \n",
      "    3      4.416083   5.168694                              \n",
      "    4      4.287536   5.169852                              \n",
      "    5      4.149753   5.174025                              \n",
      "    6      4.161283   5.172613                              \n",
      "    7      4.239572   5.173017                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.173016836298978]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr/10, 1, cycle_len=8, stepper=VAEStepper, use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_out(val_dl, model, interval=(0,10)):\n",
    "    \n",
    "    model.eval()\n",
    "    out = []\n",
    "    ds = next(iter(val_dl))\n",
    "    c0,c1,x, y = ds\n",
    "    bs, sl = x.size()\n",
    "    model.wdrop=0\n",
    "    #x = x.long()\n",
    "    #if use_cuda:\n",
    "    #    x = x.cuda()\n",
    "    decoded, mu, logvar, z = model((c0,c1,x))\n",
    "    #z = V(torch.randn((bs,model.latent_sz)))\n",
    "    probs = model.inference(z)\n",
    "    #preds = np.array(decoded.max(2)[1])\n",
    "    preds = np.array(probs.max(2)[1])\n",
    "    for i in range(interval[0], interval[-1]):\n",
    "        out.append([' '.join(itos[o] for o in x[:,i] if o not in [1,2]), \\\n",
    "                   ' '.join(itos[o] for o in preds[:,i] if o not in [1,2]), \\\n",
    "                   ' '.join(itos[o] for o in y[:,i] if o not in [1,2])])\n",
    "    return out,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH=50\n",
    "out,z = produce_out(val_seq2seq_dl, learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'never conductor , interest short xxunk since xxunk mind same as can xxunk this empire love ! wretch ! understanding monstrous , so i]f xxunk out must beyond art wounded love hope a , of are plague do t]he two these , change am , , mean , who h]e , vital does is man i were lock three threw tell visible blame ('"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'never conductor , interest short xxunk since xxunk mind same as can xxunk this empire love ! wretch ! understanding monstrous , so i]f xxunk out must beyond art wounded love hope a , of are plague do t]he two these , change am , , mean , who h]e , vital does is man i were lock three threw tell visible blame ('"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thus , the is a bird - born , , , , the most , that they is lost and steel .'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(start, end, steps):\n",
    "\n",
    "    interpolation = np.zeros((start.shape[0], steps + 2))\n",
    "\n",
    "    for dim, (s,e) in enumerate(zip(start,end)):\n",
    "        interpolation[dim] = np.linspace(s,e,steps+2)\n",
    "\n",
    "    return interpolation.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = torch.randn([latent_sz]).numpy()\n",
    "z2 = torch.randn([latent_sz]).numpy()\n",
    "z = V(torch.from_numpy(interpolate(start=z1, end=z2, steps=8)).float())\n",
    "samples = learn.model.inference(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10, 20003])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thus the thoughts a thousand , , , and , , , and mind of more and mind it and .',\n",
       " 'thus all in the sun , , my to to his mind , as is the in the our',\n",
       " 'thus the the way , hard me in your , is of in , his breast , and the same . . . . .',\n",
       " 'thus , that nature the a means the minds the , , , , and the same for lost . years .',\n",
       " 'thus words thoughts , in the mind was at to he has , and have it . be other .',\n",
       " 'thus , the the same is been upon us , , , and the the mind of your mind . i . .',\n",
       " 'thus , which kind may the mind , as is one are in , and .',\n",
       " 'thus than , , this s , heart , , , and make the of made by a a passion . .',\n",
       " 'thus - the in the is that , as as the the the whole of our .',\n",
       " 'thus the thoughts that this , , my the dark , and - , my heart . and . .']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = np.array(samples.max(2)[1])\n",
    "samples = samples.T\n",
    "[' '.join(itos[o] for o in sample if o not in [0,1,2]) for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
