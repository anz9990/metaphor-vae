{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/projects/jadlg_rnn/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>text</th>\n",
       "      <th>dictionary</th>\n",
       "      <th>context</th>\n",
       "      <th>provenance</th>\n",
       "      <th>comments</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>created_at</th>\n",
       "      <th>theme</th>\n",
       "      <th>id</th>\n",
       "      <th>reviewed_on</th>\n",
       "      <th>metaphor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3213.0</td>\n",
       "      <td>Logitians use to clap a Proposition,&lt;br&gt;\\r\\n A...</td>\n",
       "      <td>Animals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Searching \"rule\" and \"reason\" in HDIS (Poetry)</td>\n",
       "      <td>In this case, not fish-trap as I originally th...</td>\n",
       "      <td>2013-10-04 14:27:45 UTC</td>\n",
       "      <td>2004-06-10 00:00:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8442</td>\n",
       "      <td>2011-06-14</td>\n",
       "      <td>A Logician is \"one, that has been broke / To R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3323.0</td>\n",
       "      <td>What raisd their Joy their love coud also rais...</td>\n",
       "      <td>Impression</td>\n",
       "      <td>I've included the entire poem</td>\n",
       "      <td>Searching \"soul\" and \"impression\" in HDIS (Poe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-09-14 19:33:39 UTC</td>\n",
       "      <td>2005-05-17 00:00:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Deep in their soules ye fair impression lay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3324.0</td>\n",
       "      <td>&lt;b&gt;If at the type our dreaming soules awake,&lt;B...</td>\n",
       "      <td>Impression</td>\n",
       "      <td>I've included the entire poem</td>\n",
       "      <td>Searching \"soul\" and \"impression\" in HDIS (Poe...</td>\n",
       "      <td>&lt;BR&gt;</td>\n",
       "      <td>2009-09-14 19:33:39 UTC</td>\n",
       "      <td>2005-05-17 00:00:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"If at the type our dreaming soules awake, / &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3407.0</td>\n",
       "      <td>In all mistakes, The Strickt, and Regular,&lt;BR&gt;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Searching \"mind\" and \"clock\" in HDIS (Poetry)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-09-14 19:33:43 UTC</td>\n",
       "      <td>2006-11-16 00:00:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"As no Man mind's those Clocks that use to go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5026.0</td>\n",
       "      <td>\"Edward, lo! to sudden fate &lt;BR&gt;\"(Weave we the...</td>\n",
       "      <td>Inhabitants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-09-14 19:38:37 UTC</td>\n",
       "      <td>2003-11-11 00:00:00 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unborn ages may crowd on the soul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_id                                               text   dictionary  \\\n",
       "0   3213.0  Logitians use to clap a Proposition,<br>\\r\\n A...      Animals   \n",
       "1   3323.0  What raisd their Joy their love coud also rais...   Impression   \n",
       "2   3324.0  <b>If at the type our dreaming soules awake,<B...   Impression   \n",
       "3   3407.0  In all mistakes, The Strickt, and Regular,<BR>...          NaN   \n",
       "4   5026.0  \"Edward, lo! to sudden fate <BR>\"(Weave we the...  Inhabitants   \n",
       "\n",
       "                         context  \\\n",
       "0                            NaN   \n",
       "1  I've included the entire poem   \n",
       "2  I've included the entire poem   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "\n",
       "                                          provenance  \\\n",
       "0     Searching \"rule\" and \"reason\" in HDIS (Poetry)   \n",
       "1  Searching \"soul\" and \"impression\" in HDIS (Poe...   \n",
       "2  Searching \"soul\" and \"impression\" in HDIS (Poe...   \n",
       "3      Searching \"mind\" and \"clock\" in HDIS (Poetry)   \n",
       "4                                               HDIS   \n",
       "\n",
       "                                            comments               updated_at  \\\n",
       "0  In this case, not fish-trap as I originally th...  2013-10-04 14:27:45 UTC   \n",
       "1                                                NaN  2009-09-14 19:33:39 UTC   \n",
       "2                                               <BR>  2009-09-14 19:33:39 UTC   \n",
       "3                                                NaN  2009-09-14 19:33:43 UTC   \n",
       "4                                                NaN  2009-09-14 19:38:37 UTC   \n",
       "\n",
       "                created_at theme     id reviewed_on  \\\n",
       "0  2004-06-10 00:00:00 UTC   NaN   8442  2011-06-14   \n",
       "1  2005-05-17 00:00:00 UTC   NaN   8591         NaN   \n",
       "2  2005-05-17 00:00:00 UTC   NaN   8592         NaN   \n",
       "3  2006-11-16 00:00:00 UTC   NaN   8698         NaN   \n",
       "4  2003-11-11 00:00:00 UTC   NaN  13518         NaN   \n",
       "\n",
       "                                            metaphor  \n",
       "0  A Logician is \"one, that has been broke / To R...  \n",
       "1  \"Deep in their soules ye fair impression lay, ...  \n",
       "2  \"If at the type our dreaming soules awake, / &...  \n",
       "3  \"As no Man mind's those Clocks that use to go ...  \n",
       "4                  Unborn ages may crowd on the soul  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'all.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text'].astype(str)\n",
    "metaphor = df['metaphor'].astype(str)\n",
    "text = [t.lower().replace('\\r','').replace('/','').replace('\"','').replace(\"'\",\"\").replace(\"\\n\",\"\").replace('<br>','').replace('<i>','').replace('--','') for t in text]\n",
    "metaphor = [t.lower().replace('\\r','').replace('/','').replace('\"','').replace(\"'\",\"\").replace(\"\\n\",\"\").replace('<br>','').replace('<i>','').replace('--','') for t in metaphor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0, c1 = [],[]\n",
    "\n",
    "for i in range(len(text)):\n",
    "    text[i] = re.sub('\\x0b','',text[i])\n",
    "    t = re.sub('<b>.*<b>',' xxmsk ',text[i]).split(' xxmsk ')\n",
    "    c0.append(t[0])\n",
    "    if len(t) > 1:  c1.append(t[1])\n",
    "    else: c1.append('')\n",
    "    #text[i] = re.sub('<.*>','',text[i])\n",
    "    #metaphor[i] = re.sub('<.*>','',metaphor[i])\n",
    "    #text[i] = re.sub('\\x0b','',text[i])\n",
    "    metaphor[i] = re.sub('\\x0b','',metaphor[i])\n",
    "    #text[i].replace('.(p','')\n",
    "    #text[i].replace(' ','')\n",
    "    #text[i].replace('.(pp','')\n",
    "    \n",
    "    #metaphor[i] = re.sub('(.*)','',metaphor[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the verse adorn again fierce war and faithful love, and truth severe, by fairy fiction dressed. in buskined measures move pale grief and pleasing pain, with ',\n",
       " '.a voice as of the cherub-choir gales from blooming eden bear; and distant warblings lessen on my ear, that lost in long futurity expire. fond impious man, thinkst thou yon sanguine cloud, raised by thy breath, has quenched the orb of day? tomorrow he repairs the golden flood, and warms the nations with redoubled ray. enough for me: with joy i see the different doom our fates assign. be thine despair and sceptered care; to triumph, and to die, are mine. he spoke, and headlong from the mountains height deep in the roaring tide he plunged to endless night. (ll. 125-44, pp. 198-200)',\n",
       " 'horror may be a tyrant of the throbbing breast')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0[5],c1[5],metaphor[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14957"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_c0 = Tokenizer.proc_all(c0,lang='en')\n",
    "tok_c1 = Tokenizer.proc_all(c1,lang='en')\n",
    "tok_tgt = Tokenizer.proc_all(metaphor,lang='en')\n",
    "len(tok_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tok_src[0], tok_tgt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def mask_sequences(texts):\n",
    "#    masked_text = []\n",
    "#    for text in texts:\n",
    "#        for token in tokenizer.tok(text):\n",
    "#            if token.pos_ == 'VERB' and not token.is_stop:\n",
    "#                text = text.replace(str(token),' xxmsk ')\n",
    "#        masked_text.append(text)\n",
    "#    return masked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masked_metaphor = mask_sequences(metaphor)\n",
    "#masked_metaphor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masked_metaphor = [text.replace(' xxmsk ','xxmsk') for text in masked_metaphor]\n",
    "#masked_metaphor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(masked_metaphor, open(path/'metaphors_masked.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masked_metaphor = pickle.load(open(path/'metaphors_masked.pkl','rb'))\n",
    "#len(masked_metaphor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def toks2ids(tok, pre,is_src=True,ovrt=False):\n",
    "    if ovrt:\n",
    "        freq = collections.Counter(p for o in tok for p in o)\n",
    "        itos = [o for o,c in freq.most_common(20000)]\n",
    "        itos.insert(0, 'xxunk')\n",
    "        itos.insert(1, 'xxpad')\n",
    "        itos.insert(2, 'xxbos')\n",
    "        #itos.insert(3, 'xxmsk')\n",
    "        stoi = collections.defaultdict(lambda: 0, {v:k for k,v in enumerate(itos)})\n",
    "        pickle.dump(itos, open(path/f'{pre}_itos.pkl', 'wb'))\n",
    "    else: \n",
    "        itos = pickle.load(open(path/f'{pre}_itos.pkl', 'rb'))\n",
    "        stoi = collections.defaultdict(lambda: 0, {v:k for k,v in enumerate(itos)})\n",
    "    return itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tok_src = Tokenizer.proc_all(masked_metaphor,lang='en')\n",
    "#tok_tgt = Tokenizer.proc_all(metaphor,lang='en')\n",
    "#len(tok_src), len(tok_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20003, 14957, 14957)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos,stoi = toks2ids(tok_c0+tok_c1+tok_tgt,'metaphors',ovrt=True)\n",
    "#itos,stoi = toks2ids(tok_tgt,'metaphors',ovrt=False)\n",
    "c0_ids = np.array([[2]+[stoi[o] for o in p] for p in tok_c0])\n",
    "c1_ids = np.array([[2]+[stoi[o] for o in p] for p in tok_c1])\n",
    "tgt_ids = np.array([[2]+[stoi[o] for o in p] for p in tok_tgt])\n",
    "len(itos),len(c0_ids),len(tgt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#c0_ids[0], tgt_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_c0,val_c0,trn_c1,val_c1,trn_tgt,val_tgt = sklearn.model_selection.train_test_split(c0_ids,c1_ids,tgt_ids,test_size=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13461, 13461, 1496, 1496)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_c0), len(trn_tgt), len(val_c0), len(val_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_c0[:2], trn_c1[:2],trn_tgt[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    header = fin.readline().split()\n",
    "    n, d = header[0], header[1]\n",
    "    data = {}\n",
    "    #partitions = [fin[:]]\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(tokens[1:], dtype=float)\n",
    "    return data, n, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs, vs, dim_en_vec = load_vectors('/home/paperspace/projects/seq2seq_bot/data/wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, c0, c1,tgt):\n",
    "        self.c0 = c0\n",
    "        self.c1 = c1\n",
    "        self.tgt = tgt\n",
    "        self.ml = 100\n",
    "    def __getitem__(self, idx):\n",
    "        return A(self.c0[idx][-self.ml:]), A(self.c1[idx][-self.ml:]), A(self.tgt[idx][-self.ml:]),A(self.tgt[idx][-self.ml:])\n",
    "    def __len__(self): return len(self.src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_seq2seq_ds = MaskDataset(trn_c0,trn_c1,trn_tgt)\n",
    "val_seq2seq_ds = MaskDataset(val_c0,val_c1,val_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64\n",
    "\n",
    "trn_samp = SortishSampler(trn_c0, lambda x: len(trn_c0[x]), bs)\n",
    "val_samp = SortSampler(val_c0, lambda x: len(val_c0[x]))\n",
    "\n",
    "trn_seq2seq_dl = DataLoader(trn_seq2seq_ds,batch_size=bs,pad_idx=1,num_workers=1,pre_pad=False, transpose_y=True, transpose=True, sampler=trn_samp)\n",
    "val_seq2seq_dl = DataLoader(val_seq2seq_ds,batch_size=bs,pad_idx=1,num_workers=1,pre_pad=False, transpose_y=True, transpose=True, sampler=val_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 64]),\n",
       " torch.Size([100, 64]),\n",
       " torch.Size([64, 100]),\n",
       " torch.Size([64, 100]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0, c1, x, y = next(iter(trn_seq2seq_dl))\n",
    "c0.size(), c1.size(), x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ModelData(path, trn_seq2seq_dl, val_seq2seq_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target, kld_weight=0):\n",
    "    decoded = input\n",
    "    sl, bs = target.size()\n",
    "    sl_in,bs_in,nc = decoded.size()\n",
    "    if sl>sl_in: decoded = F.pad(decoded, (0,0,0,0,0,sl-sl_in))\n",
    "    decoded = decoded[:sl]\n",
    "    return F.cross_entropy(decoded.view(-1,nc), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w])\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,vs,vecs,itos,em_sz,latent_sz,nh,nl=2, dropf=1,wdrop=0,kld_weight=1e-3):\n",
    "        super().__init__()\n",
    "        self.initrange=0.1\n",
    "        self.wdrop,self.kld_weight = wdrop,kld_weight\n",
    "        self.nl,self.nh, self.vs,self.em_sz,self.latent_sz = nl,nh,vs,em_sz,latent_sz\n",
    "        #encoder\n",
    "        self.emb_enc = create_emb(vecs,itos,em_sz)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15*dropf)\n",
    "        self.gru_enc = nn.GRU(em_sz, nh, num_layers=nl, dropout=0.25*dropf, bidirectional=True)\n",
    "        self.out_drop = nn.Dropout(0.35*dropf)\n",
    "        #latent space layers\n",
    "        self.h2m = nn.Linear(nh*nl*2*3, latent_sz)\n",
    "        self.h2m.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.h2log = nn.Linear(nh*nl*2*3, latent_sz)\n",
    "        self.h2log.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.z2h = nn.Linear(latent_sz, nh*nl*2*3)\n",
    "        #self.z2h.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        #decoder\n",
    "        self.gru_dec = nn.GRU(em_sz+latent_sz, nh*2*3, num_layers=nl, dropout=0.25*dropf)\n",
    "        self.out = nn.Linear(nh*2*3, vs)\n",
    "        self.out.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.pr_force = 1.\n",
    "        \n",
    "    def forward(self, inp, y=None):\n",
    "        #encode\n",
    "        c0,c1,x = inp\n",
    "        x = x.transpose(1,0)\n",
    "        sl,bs = x.size()\n",
    "        hidden = self.initHidden(bs) # nl*bs*nh\n",
    "        \n",
    "        emb1 = self.emb_enc_drop(self.emb_enc(c0)) #sl*bs*em_sz\n",
    "        _, hidden = self.gru_enc(emb1,hidden) #enc_out: sl*bs*nh, hidden: (2*nl)*bs*nh\n",
    "        h1 = hidden.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "        \n",
    "        emb2 = self.emb_enc_drop(self.emb_enc(x)) #sl*bs*em_sz\n",
    "        _, hidden = self.gru_enc(emb2,hidden) #enc_out: sl*bs*nh, hidden: (2*nl)*bs*nh\n",
    "        h2 = hidden.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "        \n",
    "        emb3 = self.emb_enc_drop(self.emb_enc(c1)) #sl*bs*em_sz\n",
    "        _, hidden = self.gru_enc(emb3,hidden) #enc_out: sl*bs*nh, hidden: (2*nl)*bs*nh\n",
    "        h3 = hidden.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "        \n",
    "        hidden = torch.cat([h1,h2,h3],2)\n",
    "        \n",
    "        mu,logvar = self.h2m(hidden.view(bs,-1)),self.h2log(hidden.view(bs,-1))\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = V(torch.randn(mu.size())) #bs*latent_sz\n",
    "        z = eps * std + mu #bs*latent_sz\n",
    "        #decode\n",
    "        hidden = self.z2h(z)\n",
    "        #hidden = self.initHidden(bs).view(self.nl,bs,self.nh*2)\n",
    "        dec_seq = x.clone()\n",
    "        #word dropout\n",
    "        if self.wdrop > 0: \n",
    "            prob = V(torch.rand(dec_seq.size())) \n",
    "            prob[(dec_seq.data - stoi['xxbos']) * (dec_seq.data - stoi['xxpad']) == 0] = 1\n",
    "            dec_seq[prob < self.wdrop] = stoi['xxunk']\n",
    "        \n",
    "        res = []\n",
    "        dec_inp = V(torch.zeros(bs)+stoi['xxbos']).long()\n",
    "        \n",
    "        for i in range(sl):\n",
    "            dec_emb = self.emb_enc(dec_inp)\n",
    "            gru_inp = torch.cat([dec_emb,z], 1).unsqueeze(0)\n",
    "            outp, hidden = self.gru_dec(gru_inp, hidden) #output: sl*bs*(nh*nl*2), hidden: (nl*2)*bs*nh\n",
    "            #hidden = hidden.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "            outp = self.out(self.out_drop(outp[0])) #bs*vs\n",
    "            res.append(outp)\n",
    "            if (random.random()>self.pr_force):\n",
    "                dec_inp = dec_seq[i]\n",
    "            else:\n",
    "                dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res), mu, logvar, z\n",
    "    \n",
    "    def inference(self,z):\n",
    "        res =[]\n",
    "        bs,_ = z.size()\n",
    "        #samples = V(torch.zeros(MAX_LENGTH, bs).long())\n",
    "        #z = V(torch.randn([bs, self.latent_sz]))\n",
    "        hidden = self.z2h(z)\n",
    "        #hidden = h = V(torch.zeros(self.nl, bs, self.nh*2*3))\n",
    "        dec_inp = V(torch.zeros(bs)+stoi['xxbos']).long()\n",
    "        for i in range(MAX_LENGTH):\n",
    "            emb = self.emb_enc(dec_inp)\n",
    "            gru_inp = torch.cat([emb,z],1).unsqueeze(0)\n",
    "            outp, hidden = self.gru_dec(gru_inp, hidden)\n",
    "            \n",
    "            outp = self.out(outp[0])\n",
    "            res.append(outp)\n",
    "            #dec_inp = V(torch.topk(outp,1,-1)[1]).squeeze(1)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            outp = F.log_softmax(outp, dim=1)\n",
    "            outp = torch.multinomial(torch.exp(outp), 1)\n",
    "            #samples[i, :] = outp.view(-1).data\n",
    "            dec_inp = V(outp.view(-1))\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs):\n",
    "        h = V(torch.zeros(self.nl*2, bs, self.nh))\n",
    "        #if torch.cuda.is_available(): h = h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_anneal_function(anneal_function, step, k, x0):\n",
    "    if anneal_function == 'logistic':\n",
    "        return float(1/(1+np.exp(-k*(step-x0))))\n",
    "    elif anneal_function == 'linear':\n",
    "        return min(1, step/x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(input, target, kld_weight):\n",
    "    decoded, mu, logvar, z = input\n",
    "    sl, bs = target.size()\n",
    "    sl_in,bs_in,nc = decoded.size()\n",
    "    if sl>sl_in: decoded = F.pad(decoded, (0,0,0,0,0,sl-sl_in))\n",
    "    decoded = decoded[:sl]\n",
    "    #loss = seq2seq_loss(decoded, target)\n",
    "    loss = F.cross_entropy(decoded.view(-1,nc), target.contiguous().view(-1))\n",
    "    KL_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    loss += KL_loss * kld_weight\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEStepper(Stepper):\n",
    "    \n",
    "    def step(self, x, y, epoch, an_f='logistic',kld_start_inc=5):\n",
    "        xtra = []\n",
    "        #self.m.wdrop = 0.1 if epoch>4 else 0\n",
    "        self.m.pr_force = (10-epoch)*0.1 if epoch<10 else 0\n",
    "        y = y.transpose(1,0)\n",
    "        output = self.m(x, y)\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "        self.opt.zero_grad()\n",
    "        loss = raw_loss = self.crit([output]+xtra, y, self.m.kld_weight)\n",
    "        loss.backward()\n",
    "        if epoch > kld_start_inc:\n",
    "            self.m.kld_weight = kl_anneal_function(an_f,epoch,self.m.kld_weight,kld_start_inc)\n",
    "        if self.clip:   # Gradient clipping\n",
    "            nn.utils.clip_grad_norm_(trainable_params_(self.m), self.clip)\n",
    "        self.opt.step()\n",
    "        return raw_loss.data.item()\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        self.m.eval()\n",
    "        xtra = []\n",
    "        #x = x[0]\n",
    "        y = y.transpose(1,0)\n",
    "        output = self.m(x, y)\n",
    "        #decoded, m, l, z = output\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "#        loss = raw_loss = self.crit([output]+xtra,y, kld_weight)\n",
    "    \n",
    "        return output, self.crit([output]+xtra,y, self.m.kld_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2488 ['em>.', 'fancys', '.(p', 'formd', 'lovd']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (emb_enc): Embedding(20003, 300, padding_idx=1)\n",
       "  (emb_enc_drop): Dropout(p=0.15)\n",
       "  (gru_enc): GRU(300, 64, num_layers=2, dropout=0.25, bidirectional=True)\n",
       "  (out_drop): Dropout(p=0.35)\n",
       "  (h2m): Linear(in_features=768, out_features=16, bias=True)\n",
       "  (h2log): Linear(in_features=768, out_features=16, bias=True)\n",
       "  (z2h): Linear(in_features=16, out_features=768, bias=True)\n",
       "  (gru_dec): GRU(316, 384, num_layers=2, dropout=0.25)\n",
       "  (out): Linear(in_features=384, out_features=20003, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nh = 64\n",
    "nl = 2\n",
    "vs = len(itos)\n",
    "em_sz = int(dim_en_vec)\n",
    "#latent_sz = em_sz\n",
    "latent_sz = 16\n",
    "vae = VAE(vs,en_vecs,itos,em_sz,latent_sz,nh,nl=nl)\n",
    "vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, SingleModel(to_gpu(vae)), opt_fn=opt_fn)\n",
    "learn.crit = vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4449dcb57ed244fda29267eecc52f13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 139/211 [00:34<00:18,  3.99it/s, loss=21.9]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(stepper=VAEStepper)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ad2d87d00c4ca5ae5141557776272e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      9.200713   9.145822  \n",
      "    1      9.16312    9.23193                               \n",
      "    2      8.730082   8.821178                              \n",
      "    3      6.104682   7.789285                              \n",
      "    4      3.669525   4.540858                              \n",
      "    5      2.826545   2.917815                              \n",
      "    6      2.497831   2.476858                              \n",
      "    7      2.26756    2.320552                              \n",
      "    8      2.171268   2.243575                              \n",
      "    9      2.134847   2.092973                              \n",
      "    10     2.061799   2.022212                              \n",
      "    11     2.049577   2.015715                              \n",
      "    12     2.005237   2.004862                              \n",
      "    13     1.95447    2.001663                              \n",
      "    14     1.995685   1.996094                              \n",
      "    15     1.94997    1.992944                              \n",
      "    16     1.976984   1.99242                               \n",
      "    17     1.909766   1.991216                              \n",
      "    18     1.93534    1.991062                              \n",
      "    19     1.912628   1.988981                              \n",
      "    20     1.864386   1.990721                              \n",
      "    21     1.897597   1.989054                              \n",
      "    22     1.873118   1.990678                              \n",
      "    23     1.897114   1.990494                              \n",
      "    24     1.87606    1.990868                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9908683440264534]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=25, stepper=VAEStepper, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('vae_metaphors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('vae_metaphors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a7dbc8beaf4f989152cb7e53bc31c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      4.960727   5.174614  \n",
      "    1      4.278578   5.172833                              \n",
      "    2      4.844539   5.17032                               \n",
      "    3      4.416083   5.168694                              \n",
      "    4      4.287536   5.169852                              \n",
      "    5      4.149753   5.174025                              \n",
      "    6      4.161283   5.172613                              \n",
      "    7      4.239572   5.173017                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.173016836298978]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr/10, 1, cycle_len=8, stepper=VAEStepper, use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_out(val_dl, model, interval=(0,10)):\n",
    "    \n",
    "    model.eval()\n",
    "    out = []\n",
    "    ds = next(iter(val_dl))\n",
    "    c0,c1,x,y = ds\n",
    "    y = y.transpose(1,0)\n",
    "    #x = x.transpose(1,0)\n",
    "    bs, sl = x.size()\n",
    "    model.wdrop=0\n",
    "    model.pr_force=1\n",
    "    #x = x.long()\n",
    "    #if use_cuda:\n",
    "    #    x = x.cuda()\n",
    "    decoded, mu, logvar, z = model((c0,c1,x))\n",
    "    #z = V(torch.randn((bs,model.latent_sz)))\n",
    "    probs = model.inference(z)\n",
    "    #preds = np.array(decoded.max(2)[1])\n",
    "    preds = np.array(probs.max(2)[1])\n",
    "    for i in range(interval[0], interval[-1]):\n",
    "        out.append([' '.join(itos[o] for o in c0[:,i] if o not in [1,2]), \\\n",
    "                    ' '.join(itos[o] for o in x[:,i] if o not in [1,2]), \\\n",
    "                    ' '.join(itos[o] for o in preds[:,i] if o not in [0,1,2]), \\\n",
    "                    ' '.join(itos[o] for o in c1[:,i] if o not in [1,2])])\n",
    "    return out,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH=100\n",
    "out,z = produce_out(trn_seq2seq_dl, learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'was the same impropriety in the same epithet bestowed upon richard iii . king of england , who , he says , was one of the best - made men of the age in which he lived : but here [ page 24 ] i must contradict the said buck , from my own knowledge . richard had , undoubtedly , one shoulder higher than the other , and his left arm was a little shrunk and contracted : but , notwithstanding the ungracious colours in which he has been drawn by the flatterers of the house of xxunk ,never wretched can may i]f minds wit oer have m]y i friendship empire pours body is wretch ! bliss my body monstrous may my like lockes art tree most love a those reason this t]he booby lifes motion the difference , though me novelty this annoyance , , hearts got xxunk i i if body , as in thy this then is need maythe least qualified subjects , and xxunk merit , his new xxunk concluded ( not without some shadow of reason ) that xxunk - xxunk being unknown to the prime minister , was a sort of negative presumption in favour of his character . this officer was accordingly [ page 28 ] placed at the head of an xxunk , and sent against the island of thin - quo , in the conquest of which he was to be supported by a squadron of xxunk already in those xxunk , under the command of the chief he - xxunk .'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[2][0]+out[2][1]+out[2][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'was the same impropriety in the same epithet bestowed upon richard iii . king of england , who , he says , was one of the best - made men of the age in which he lived : but here [ page 24 ] i must contradict the said buck , from my own knowledge . richard had , undoubtedly , one shoulder higher than the other , and his left arm was a little shrunk and contracted : but , notwithstanding the ungracious colours in which he has been drawn by the flatterers of the house of xxunk ,the the who , to thousand to to been , to much the , that had the same impression of had and mind were a as , and they were , , into to mind , of the soul , , the the thing , and the not be have to is the , that the soul is been the mind mind , we own own empire to , ,the least qualified subjects , and xxunk merit , his new xxunk concluded ( not without some shadow of reason ) that xxunk - xxunk being unknown to the prime minister , was a sort of negative presumption in favour of his character . this officer was accordingly [ page 28 ] placed at the head of an xxunk , and sent against the island of thin - quo , in the conquest of which he was to be supported by a squadron of xxunk already in those xxunk , under the command of the chief he - xxunk .'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[2][0]+out[2][2]+out[2][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('never wretched can may i]f minds wit oer have m]y i friendship empire pours body is wretch ! bliss my body monstrous may my like lockes art tree most love a those reason this t]he booby lifes motion the difference , though me novelty this annoyance , , hearts got xxunk i i if body , as in thy this then is need may',\n",
       " 'the the who , to thousand to to been , to much the , that had the same impression of had and mind were a as , and they were , , into to mind , of the soul , , the the thing , and the not be have to is the , that the soul is been the mind mind , we own own empire to , ,')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[2][1], out[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(start, end, steps):\n",
    "\n",
    "    interpolation = np.zeros((start.shape[0], steps + 2))\n",
    "\n",
    "    for dim, (s,e) in enumerate(zip(start,end)):\n",
    "        interpolation[dim] = np.linspace(s,e,steps+2)\n",
    "\n",
    "    return interpolation.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = torch.randn([latent_sz]).numpy()\n",
    "z2 = torch.randn([latent_sz]).numpy()\n",
    "z = V(torch.from_numpy(interpolate(start=z1, end=z2, steps=8)).float())\n",
    "samples = learn.model.inference(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10, 20003])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the me minds be mind , , , ,',\n",
       " 'the up the , the own , and he is impression with to and to be , and of a to be , thousand in in the heart and of - were , and',\n",
       " 'the the same of ideas , which , the be the to the , and the thing of the mind ,',\n",
       " ', the the , and it are the and the mind of the , and is is , to , it be . it it of is the more . to .',\n",
       " 'the the , , that the the , the - , the , much , and the same of the heart mind ,',\n",
       " 'the ! heart , in ,',\n",
       " 'much , , that , the impression , the mind little of , and the , , the and , and the the of and the the mind of the , longer , the the is the and be the the , that the the the - , , the of which is in the minds , and the , not , are , that man , which the mind are been been , and the into into the the the in image from the , . the .',\n",
       " 'had a the the of the a the same manner , ideas , had , he minds are , the , and , well in , , the mind , and , as , and own , the , the , and the it same of the . , is not by of the body , it the be - .',\n",
       " 'the , i the , the i , the , which and , and the mind are , the soul of the , is soul of the soul to be to be , , and mind , , the the , mind of and and the , and the the same , of the .',\n",
       " 'the the the the same of the , , the own , , the own , and mind of the the man , and , and , and the of , soul of the own . .']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = np.array(samples.max(2)[1])\n",
    "samples = samples.T\n",
    "[' '.join(itos[o] for o in sample if o not in [0,1,2]) for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
